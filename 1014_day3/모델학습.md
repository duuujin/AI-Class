# 과적합
- 훈련(기존 데이터)에서는 좋은 성능을 보이지만, 실제 테스트(새로운 데이터)에서는 성능이 나빠지는 현상

# 과적합(Overfiting)
- 머신러닝모델이 훈련데이터(Training Data)에만 너무 익숙해져서, 데이터의 중요한 패턴을 넘어 사소한잡음(noise)까지 전부 외워버리는 현상
- 이미 학습한 훈련데이터에서는 좋은성능을 보이지만, 테스트데이터(새로운데이터)에서는 낮은성능을 보임
- 일반화를 하지 못하고, 훈련데이터에 따라 예측이 크게 흔들림

# 과소적합(Underfiting)
- 모델이 너무 단순해서 훈련데이터의 핵심적인 패턴조차 제대로 학습하지 못한 상태
- 모델의 성능은 훈련데이터에서도 낮고, 테스트데이터에서도 낮음
- 그러면, 모델이과적합(Overfiting) 혹은과소적합(Underfiting) 됐는지는어떻게알까?

# 데이터분리
- 주어진데이터을훈련데이터와테스트데이터로분리
- 훈련데이터: 모델을학습시키는용도로활용
- 테스트데이터: 모델이얼마나새로운데이터를잘예측하는지일반화성능을최종평가하는용도
    - (학습된모델이과적합(Overfitting)됐는지확인)
- 일반적으로 7:3, 8:2 (훈련:테스트)

# 데이터분리–코드
- train_test_split(): 주어진 데이터을 훈련데이터와 테스트데이터로 분리하는 함수
- test_size=0.3 :전체 데이터중30%를 테스트용, 나머지70%를 훈련용으로 나누겠다는 의미
- random_state=42: 이 숫자를 고정 해놓으면 코드를 다시 시작해도 동일한 랜덤값이 배정됨(아무값이나가능)
- stratify=y
    - 원본 데이터의 정답 비율을 분할된 데이터셋에 동일한 비율로 나눠주는 옵션
    - 훈련데이터에 ‘정상’ 메일만 들어가고, 테스트데이터에 ‘스팸’ 메일만 들어가는것을 방지 할 수 있음
    - 분류문제에서는 필수

# 데이터분리를했으니이제진짜학습시작??
- 아니요
- 이제 데이터를 분리 했을뿐, 데이터 전처리를 아직 진행하지 않았음
- 결측치, 임베딩, 스케일링작업이필요
# 스케일링
- 각 특성의 단위를 맞춰서 모델이 공평하게 학습하도록 만드는 과정
- 마치 키(180cm)와 몸무게(70kg)를 비슷한 범위의 값 으로 조정
- 대표적인 방법으로 표준화와 정규화가 있음

# [복습] 스케일링-표준화
- 모델에게 ‘나이’와 ‘연봉’데이터를 그대로 주면 어떻게 될까?
    - 값의 범위가 훨씬 큰 ‘연봉’을 더 중요한 정보로 착각할 수 있음
- 제 각각인 데이터의 단위를 공평하게 맞춰주는 작업
- 데이터의 평균을0, 표준편차를1로 변환
    - 평균 0 : 모든 데이터를 0을 기준으로 맞춤
    - 표준편차 1 : 각 데이터가 평균으로부터 얼마나 떨어져있는지(표준편차)를 기준으로 데이터의 스케일을 조절
- 특징
    - 이상치에 상대적으로 덜 민감하고, 정규분포를 따를때 효과적
        (*이상치: 다른값들에비해극단적으로다른값)
    - 모든 특성에 공평한 영향력을 부여
    - 경사하강법, SVM, 거리기반 알고리즘의 성능 향상

# 스케일링–표준화-코드
- 훈련 데이터의 표준화를 위한 평균과 표준편차를 구하고, 데이터표준화 진행
❖주의) 테스트데이터의 표준화는 반드시 “훈련데이터의 평균/표준편차”를 활용 해야함!!!!!
- 테스트데이터는 아직 학습하지않은 미래의 데이터
- 테스트데이터의 평균/표준편차를scaler에 반영한다면, 정답을 미리 훔쳐본것과 같아짐
- 이렇게 유출된 정보로 학습한모델은 실제 현실에서 제대로된 성능이 나오지 않음