# 거대 언어 모델의 평가
- 평가(Evaluation) : 구축한 시스템(e.g. 코드 or 앱)이 실제로 잘 동작하는 지를 확인하는 단계
    - 평가의 3요소
        1. 목표: 시스템으로 무엇을 달성하고자 하는지
        2. 평가 방법 : 어떤 방법으로 평가할 것인지
        3. 평가 지표 : 어떻게 성공 여부를 판단할 것인지
- AI 모델의 평가 : "테스트 데이터"
    - 핵심 과정 : 학습 단계에서 본 적이 없고, 질문과 정답을 알고 있음
    - 예시: 감정 분류
        1. 목표 : 주어진 입력 텍스트의 감정을 올바르게 예측하는 것
        2. 평가 방법 : AI모델의 예측 감정과 사람이 작성한 정답을 비교하는 것
        3. 평가 지표 : 테스트 데이터 셋에서의 평균 정확도
- 특정 테스크에서 학습된 기존 AI 모델들과 달리, 거대 언어 모델은 다양한 테스크에 대해 동시에 학습됨
    - 따라서, 거대 언어 모델의 성능을 올바르게 평가하기 위해서는 많은 테스크에서의 성능을 종합적으로 판단해야함
    - 또한, 디코딩 알고리즘, 입력 프롬프트에 따라 같은 질문에 대해서도 예측이 바뀌므로, 공평한 비교를 위해서는 해당 부분도 고려해야함

# 거대 언어 모델 평가 방법의 종류
- 정답이 정해진 경우
    - 평가 방법 : 예측과 정답을 비교하여 일치도를 측정(정확도(Accuracy))
- 정답이 정해져 있지 않은 경우
    - 평가 방법 #1 : 사람이 임의의 정답을 작성 및 이와 예측을 비교
    - 평가 방법 #2 : 정답과 무관하게 생성 텍스트 자체의 품질만을 측정
    - 평가 방법 #3 : 생성된 텍스트의 "상대적 선호"를 평가
    - 단순한 등장 확률이 아니라, 여러가지 측면에서 평가를 하고 싶다면?
        - 예: 창의성, 유창성, 가독성 등 -> 각각에 부합하는 평가지표를 따로 설계하는 것은 굉장히 어려움
        - 기존 해결 방법 : 전문가를 고용하여 평가를 맡김
        - 거대 언어 모델로 해당 역할을 대신 수행하게 하면 안될까?

## 정답이 정해져 있지 않은 경우
- 평가 방법 #3 : 생성된 텍스트의 "상대적 선호"를 평가할 수도 있음
- 대표 예시 : LMArena -> 그러나 높은 평가 비용 및 시간을 필요로 함 -> 거대 언어로 대체한다면? 
    - 실제 유저 피드백을 활용하였으며, 거대 언어 모델 성능 측정 방법 중 가장 신뢰성 있는 방법 중 하나로 여겨짐

# 거대 언어 모델을 활용한 평가
- LLM-as-judge(or G-Eval) : 거대 언어 모델을 통해 생성 텍스트를 평가
    1. 유저는 다음과 같은 정보를 제공 1. 풀고자 하는 테스크(e.g. 질문) 2. 평가하고자 하는 텍스트 3. 평가 기준을 제공
    2. 거대언어모델은 평가 결과(점수,이유)를 제공
- GPT-4를 활용한 평가는 기존 평가 지표(e.g. ROUGE)보다 더 사람과 유사한 결과를 보임
- LLaMA3 학습을 위한 데이터 필터링에도 사용되는 등 다양한 어플리케이션에서 이미 활용되고 있음
- 그러나, 해당 평가 방식은 몇가지 한계점을 가지고 있음 -> 이를 인지하고 보완하여 활용하는 것이 필요
    1. 위치 편향 : 특정 위치의 응답을 상대적으로 선호(e.g. 첫번째 응답 > 두번째 응답)
    2. 길이 편향 : 품질과 무관하게 길이가 긴 응답을 상대적으로 선호
    3. 자기 선호 편향 : 생성 모델이 평가 모델과 같은 경우. 이를 선호